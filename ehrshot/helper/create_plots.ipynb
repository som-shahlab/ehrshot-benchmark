{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Sizes (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "output_path_context = \"../../EHRSHOT_ASSETS/figures/performance_context_sizes.png\"\n",
    "\n",
    "# Process data\n",
    "qwen_data = \" 0.672 (0.648 - 0.696), 0.759 (0.736 - 0.782), 0.767 (0.742 - 0.793), 0.774 (0.749 - 0.799), 0.743 (0.716 - 0.770)\"\n",
    "llama_data = \"0.680 (0.653 - 0.707), 0.744 (0.721 - 0.767), 0.766 (0.744 - 0.788), 0.742 (0.714 - 0.769), 0.738 (0.708 - 0.769)\"\n",
    "\n",
    "# Context sizes and performance data\n",
    "context_sizes = [512, 1024, 2048, 4096, 8192]\n",
    "\n",
    "def parse_data_string(data):\n",
    "    # Extract means, lower, and upper using regex\n",
    "    matches = re.findall(r\"([\\d.]+) \\(([\\d.]+) - ([\\d.]+)\\)\", data)\n",
    "\n",
    "    # Separate into lists\n",
    "    means = [float(match[0]) for match in matches]\n",
    "    lower = [float(match[1]) for match in matches]\n",
    "    upper = [float(match[2]) for match in matches]\n",
    "    return means, lower, upper\n",
    "\n",
    "gte_means, gte_lower, gte_upper = parse_data_string(qwen_data)\n",
    "llama_means, llama_lower, llama_upper = parse_data_string(llama_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "# Style configuration\n",
    "plt.style.use('seaborn-v0_8-paper')\n",
    "plt.rcParams.update({\n",
    "    'font.size': 10,\n",
    "    'axes.titlesize': 12,\n",
    "    'axes.labelsize': 10,\n",
    "    'xtick.labelsize': 8,\n",
    "    'ytick.labelsize': 8,\n",
    "    'legend.fontsize': 8,\n",
    "    'figure.dpi': 180,\n",
    "    'savefig.bbox': 'tight',\n",
    "    'lines.linewidth': 1.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.3\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data strings\n",
    "qwen_data = \"0.672 (0.648 - 0.696), 0.759 (0.736 - 0.782), 0.767 (0.742 - 0.793), 0.774 (0.749 - 0.799), 0.743 (0.716 - 0.770)\"\n",
    "llama_data = \"0.680 (0.653 - 0.707), 0.744 (0.721 - 0.767), 0.766 (0.744 - 0.788), 0.742 (0.714 - 0.769), 0.738 (0.708 - 0.769)\"\n",
    "context_sizes = [512, 1024, 2048, 4096, 8192]\n",
    "\n",
    "output_path_png = \"../../EHRSHOT_ASSETS/figures_ben/context_size_performance_adapted.png\"\n",
    "output_path_pdf = \"../../EHRSHOT_ASSETS/figures_ben/context_size_performance_adapted.pdf\"\n",
    "\n",
    "# Parse the data strings into means and confidence intervals\n",
    "def parse_data_string(data):\n",
    "    matches = re.findall(r\"([\\d.]+) \\(([\\d.]+) - ([\\d.]+)\\)\", data)\n",
    "    means = [float(m[0]) for m in matches]\n",
    "    lower = [float(m[1]) for m in matches]\n",
    "    upper = [float(m[2]) for m in matches]\n",
    "    return means, lower, upper\n",
    "\n",
    "# Parsed data\n",
    "qwen_means, qwen_lower, qwen_upper = parse_data_string(qwen_data)\n",
    "llama_means, llama_lower, llama_upper = parse_data_string(llama_data)\n",
    "\n",
    "# Define colors and markers consistent with other figures\n",
    "color_qwen = \"#1F78B4\"  # Blue for Qwen\n",
    "color_llama = \"#FF7F00\"  # Orange for Llama\n",
    "marker_qwen = \"o\"  # Circle for Qwen\n",
    "marker_llama = \"s\"  # Square for Llama\n",
    "\n",
    "# Initialize the plot\n",
    "plt.style.use(\"seaborn-v0_8-paper\")\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=180)\n",
    "\n",
    "# Clean plot: remove top and right spines\n",
    "# ax.spines[\"top\"].set_visible(False)\n",
    "# ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# Title and axis labels\n",
    "ax.set_title(\"Performance Across Context Sizes\", fontsize=14, pad=10, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Input Context Size\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Macro AUROC (95% CI)\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "# Logarithmic x-axis for context sizes\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xticks(context_sizes)\n",
    "ax.set_xticklabels(context_sizes, fontsize=10)\n",
    "ax.set_ylim(0.64, 0.81)\n",
    "ax.set_yticks(np.arange(0.65, 0.81, 0.05))\n",
    "\n",
    "# Horizontal gridlines for clarity\n",
    "ax.grid(visible=True, which=\"major\", axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# Plot Qwen data\n",
    "ax.plot(context_sizes, qwen_means, label=\"GTE-Qwen2-7B\", marker=marker_qwen, linestyle=\"-\", linewidth=2, color=color_qwen)\n",
    "ax.fill_between(context_sizes, qwen_lower, qwen_upper, color=color_qwen, alpha=0.15)\n",
    "\n",
    "# Plot Llama data\n",
    "ax.plot(context_sizes, llama_means, label=\"LLM2Vec-Llama-3.1-8B\", marker=marker_llama, linestyle=\"-\", linewidth=2, color=color_llama)\n",
    "ax.fill_between(context_sizes, llama_lower, llama_upper, color=color_llama, alpha=0.15)\n",
    "\n",
    "# Legend for model names\n",
    "legend_elements = [\n",
    "    plt.Line2D([0], [0], marker=marker_qwen, color=color_qwen, label=\"GTE-Qwen2-7B\", linestyle=\"None\", markersize=8),\n",
    "    plt.Line2D([0], [0], marker=marker_llama, color=color_llama, label=\"LLM2Vec-Llama-3.1-8B\", linestyle=\"None\", markersize=8),\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc=\"best\", frameon=False, fontsize=10, title=\"Model Names\")\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "output_dir = os.path.dirname(output_path_png)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "plt.savefig(output_path_png, dpi=300, bbox_inches='tight')\n",
    "plt.savefig(output_path_pdf, dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Updated models with unique colors and markers\n",
    "models = [\n",
    "    {\"name\": \"CLIMBR-T-Base\", \"million_parameters\": 141, \"performance\": (0.746, 0.769, 0.792), \"color\": \"#1F78B4\", \"marker\": \"X\", \"type\": \"CLIMBR\"},\n",
    "    {\"name\": \"GTE-Qwen2-7B\", \"million_parameters\": 7000, \"performance\": (0.749, 0.774, 0.798), \"color\": \"#FF7F00\", \"marker\": \"o\", \"type\": \"LLM\"},\n",
    "    {\"name\": \"LLM2Vec-Llama-3.1-8B\", \"million_parameters\": 8000, \"performance\": (0.714, 0.742, 0.769), \"color\": \"#FF7F00\", \"marker\": \"s\", \"type\": \"LLM\"},\n",
    "    {\"name\": \"GTE-Qwen2-1.5B\", \"million_parameters\": 1500, \"performance\": (0.732, 0.757, 0.783), \"color\": \"#FF7F00\", \"marker\": \"^\", \"type\": \"LLM\"},\n",
    "    {\"name\": \"LLM2Vec-Llama-2-1.3B\", \"million_parameters\": 1300, \"performance\": (0.627, 0.652, 0.676), \"color\": \"#FF7F00\", \"marker\": \"D\", \"type\": \"LLM\"},\n",
    "    {\"name\": \"DeBERTaV3-large\", \"million_parameters\": 434, \"performance\": (0.656, 0.683, 0.711), \"color\": \"#8C564B\", \"marker\": \"p\", \"type\": \"BERT\"},\n",
    "    {\"name\": \"DeBERTaV3-base\", \"million_parameters\": 183, \"performance\": (0.657, 0.686, 0.716), \"color\": \"#8C564B\", \"marker\": \"H\", \"type\": \"BERT\"},\n",
    "    {\"name\": \"Bio_ClinicalBERT\", \"million_parameters\": 110, \"performance\": (0.682, 0.709, 0.736), \"color\": \"#8C564B\", \"marker\": \"X\", \"type\": \"BERT\"},\n",
    "]\n",
    "\n",
    "# Initialize the plot\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=180)\n",
    "\n",
    "# Title and axis labels\n",
    "ax.set_title(\"Clinical Prediction Performance vs Model Size\", fontsize=16, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Model Parameters (Millions, Log Scale)\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Macro AUROC (95% CI)\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "# Set x and y scales\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlim(50, 20000)\n",
    "ax.set_ylim(0.60, 0.81)\n",
    "\n",
    "# Add grid with logarithmic spacing\n",
    "ax.grid(visible=True, which=\"both\", axis=\"x\", linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# Plot data points with confidence intervals\n",
    "for model in models:\n",
    "    x = model[\"million_parameters\"]\n",
    "    mean = model[\"performance\"][1]\n",
    "    lower = model[\"performance\"][0]\n",
    "    upper = model[\"performance\"][2]\n",
    "    color = model[\"color\"]\n",
    "    marker = model[\"marker\"]\n",
    "\n",
    "    # Plot the data points and confidence intervals\n",
    "    ax.errorbar(\n",
    "        x, mean, yerr=[[mean-lower], [upper-mean]],\n",
    "        fmt=marker, color=color, markersize=10, alpha=0.8, capsize=3, label=model[\"name\"]\n",
    "    )\n",
    "\n",
    "# Create grouped legends\n",
    "# Legend 1: Model Types (colors)\n",
    "model_type_legend_elements = [\n",
    "    plt.Line2D([0], [0], marker=\"X\", color=\"#1F78B4\", label=\"CLIMBR\", linestyle=\"None\", markersize=8),\n",
    "    plt.Line2D([0], [0], marker=\"o\", color=\"#FF7F00\", label=\"LLM Models\", linestyle=\"None\", markersize=8),\n",
    "    plt.Line2D([0], [0], marker=\"p\", color=\"#8C564B\", label=\"BERT Models\", linestyle=\"None\", markersize=8),\n",
    "]\n",
    "\n",
    "# Legend 2: Model Names (symbols)\n",
    "model_name_legend_elements = [\n",
    "    plt.Line2D([0], [0], marker=model[\"marker\"], color=model[\"color\"], label=model[\"name\"],\n",
    "               linestyle=\"None\", markersize=8) for model in models\n",
    "]\n",
    "\n",
    "# Add legends outside the plot with better alignment\n",
    "leg1 = ax.legend(handles=model_type_legend_elements, loc=\"upper left\", bbox_to_anchor=(1.02, 1), fontsize=8, title=\"Model Types\", frameon=False)\n",
    "leg1._legend_box.align = \"left\"\n",
    "\n",
    "leg2 = ax.legend(handles=model_name_legend_elements, loc=\"lower left\", bbox_to_anchor=(1.02, 0.), fontsize=8, title=\"Model Names\", frameon=False)\n",
    "leg2._legend_box.align = \"left\"\n",
    "\n",
    "ax.add_artist(leg1)  # Ensure first legend remains in place\n",
    "\n",
    "ax.add_artist(leg1)  # Manually add the first legend to avoid overlap\n",
    "\n",
    "# Adjust layout\n",
    "# plt.tight_layout()\n",
    "\n",
    "# Save or display the plot\n",
    "plt.savefig(\"../../EHRSHOT_ASSETS/figures_ben/performance_with_two_legends.png\", dpi=300, bbox_inches='tight')\n",
    "plt.savefig(\"../../EHRSHOT_ASSETS/figures_ben/performance_with_two_legends.pdf\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Sizes (updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from plot import (\n",
    "    _plot_unified_legend,\n",
    ")\n",
    "\n",
    "qwen_data = \"0.672 (0.648 - 0.696), 0.759 (0.736 - 0.782), 0.767 (0.742 - 0.793), 0.774 (0.749 - 0.799), 0.743 (0.716 - 0.770)\"\n",
    "llama_data = \"0.680 (0.653 - 0.707), 0.744 (0.721 - 0.767), 0.766 (0.744 - 0.788), 0.742 (0.714 - 0.769), 0.738 (0.708 - 0.769)\"\n",
    "context_sizes = [512, 1024, 2048, 4096, 8192]\n",
    "\n",
    "output_path_png = \"../../EHRSHOT_ASSETS/figures_ben/context_size_performance_adapted.png\"\n",
    "output_path_pdf = \"../../EHRSHOT_ASSETS/figures_ben/context_size_performance_adapted.pdf\"\n",
    "\n",
    "# Parse the data strings into means and confidence intervals\n",
    "def parse_data_string(data):\n",
    "    matches = re.findall(r\"([\\d.]+) \\(([\\d.]+) - ([\\d.]+)\\)\", data)\n",
    "    means = [float(m[0]) for m in matches]\n",
    "    lower = [float(m[1]) for m in matches]\n",
    "    upper = [float(m[2]) for m in matches]\n",
    "    return means, lower, upper\n",
    "\n",
    "# Parsed data\n",
    "qwen_means, qwen_lower, qwen_upper = parse_data_string(qwen_data)\n",
    "llama_means, llama_lower, llama_upper = parse_data_string(llama_data)\n",
    "\n",
    "# Define colors and markers consistent with other figures\n",
    "color_llama = \"#33a02c\"  \n",
    "color_qwen= \"#FF7F00\" \n",
    "marker_qwen = \"o\" \n",
    "marker_llama = \"o\" \n",
    "\n",
    "# Initialize the plot\n",
    "plt.style.use(\"seaborn-v0_8-paper\")\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=180)\n",
    "\n",
    "# Title and axis labels\n",
    "ax.set_title(\"Performance Across Context Sizes\", fontsize=12, pad=10, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Input Context Size (log scale)\", fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Macro AUROC (95% CI)\", fontweight=\"bold\")\n",
    "\n",
    "# Logarithmic x-axis for context sizes\n",
    "ax.set_xscale(\"log\")\n",
    "ax.minorticks_off()\n",
    "ax.set_xticks(context_sizes)\n",
    "ax.set_xticklabels(context_sizes, fontsize=10)\n",
    "ax.set_ylim(0.64, 0.81)\n",
    "ax.set_yticks(np.arange(0.65, 0.81, 0.05))\n",
    "\n",
    "# Improve grid\n",
    "# ax.grid(visible=True, which=\"both\", linestyle=\"-\", alpha=0.2)\n",
    "# ax.grid(True, which='minor', linestyle=':', alpha=0.2)\n",
    "\n",
    "# Format axes\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "\n",
    "# Plot Qwen data\n",
    "ax.plot(context_sizes, qwen_means, label=\"GTE-Qwen2-7B\",\n",
    "        marker=marker_qwen, linestyle=\"-\", linewidth=1.5,\n",
    "        markersize=8, color=color_qwen,\n",
    "        markeredgecolor=\"white\", markeredgewidth=1.5)\n",
    "ax.fill_between(context_sizes, qwen_lower, qwen_upper, color=color_qwen, alpha=0.15)\n",
    "\n",
    "# Plot Llama data\n",
    "ax.plot(context_sizes, llama_means, label=\"LLM2Vec-Llama-3.1-8B\",\n",
    "        marker=marker_llama, linestyle=\"-\", linewidth=1.5,\n",
    "        markersize=8, color=color_llama,\n",
    "        markeredgecolor=\"white\", markeredgewidth=1.5)\n",
    "ax.fill_between(context_sizes, llama_lower, llama_upper, color=color_llama, alpha=0.15)\n",
    "\n",
    "# Legend for model names\n",
    "legend_elements = [\n",
    "    plt.Line2D([0], [0], marker=marker_qwen, color=color_qwen, label=\"GTE-Qwen2-7B\", linestyle=\"None\", markersize=8),\n",
    "    plt.Line2D([0], [0], marker=marker_llama, color=color_llama, label=\"LLM2Vec-Llama-3.1-8B\", linestyle=\"None\", markersize=8),\n",
    "]\n",
    "# ax.legend(handles=legend_elements, loc=\"lower left\", frameon=False, fontsize=10, title=\"Model Names\")\n",
    "_plot_unified_legend(fig, np.array([[ax]]), fontsize=9)\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(output_path_png, dpi=300, bbox_inches='tight')\n",
    "plt.savefig(output_path_pdf, dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from plot import (\n",
    "    _plot_unified_legend,\n",
    ")\n",
    "\n",
    "# Data strings (reference: https://docs.google.com/presentation/d/1THx_hGoxF6yGM_jYnqsNMcPufXsEKP0xeX87KTW7UmU/edit?slide=id.g34372a89f79_0_23#slide=id.g34372a89f79_0_23)\n",
    "qwen_data = \"0.760 (0.732 - 0.788) 0.768 (0.743 - 0.792) 0.773 (0.746 - 0.801) 0.765 (0.743 - 0.787) 0.762 (0.738 - 0.787) 0.755 (0.730 - 0.780)\"\n",
    "llama_data = \"0.761 (0.735 - 0.786) 0.762 (0.735 - 0.789) 0.767 (0.739 - 0.794) 0.748 (0.719 - 0.776) 0.736 (0.706 - 0.767) 0.734 (0.706 - 0.761)\" \n",
    "time_windows = [\"1 day\", \"1 week\", \"1 month\", \"1 year\", \"3 years\", \"full\"]\n",
    "time_windows_ticks = np.arange(1, len(time_windows) + 1)\n",
    "\n",
    "output_path_png = \"../../EHRSHOT_ASSETS/figures_ben/context_size_performance_adapted.png\"\n",
    "output_path_pdf = \"../../EHRSHOT_ASSETS/figures_ben/context_size_performance_adapted.pdf\"\n",
    "\n",
    "# Parse the data strings into means and confidence intervals\n",
    "def parse_data_string(data):\n",
    "    matches = re.findall(r\"([\\d.]+) \\(([\\d.]+) - ([\\d.]+)\\)\", data)\n",
    "    means = [float(m[0]) for m in matches]\n",
    "    lower = [float(m[1]) for m in matches]\n",
    "    upper = [float(m[2]) for m in matches]\n",
    "    return means, lower, upper\n",
    "\n",
    "# Parsed data\n",
    "qwen_means, qwen_lower, qwen_upper = parse_data_string(qwen_data)\n",
    "llama_means, llama_lower, llama_upper = parse_data_string(llama_data)\n",
    "\n",
    "# Define colors and markers consistent with other figures\n",
    "color_llama = \"#33a02c\"  \n",
    "color_qwen= \"#FF7F00\" \n",
    "marker_qwen = \"o\" \n",
    "marker_llama = \"o\" \n",
    "\n",
    "# Initialize the plot\n",
    "plt.style.use(\"seaborn-v0_8-paper\")\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=180)\n",
    "\n",
    "# Clean plot: remove top and right spines\n",
    "# ax.spines[\"top\"].set_visible(False)\n",
    "# ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# Title and axis labels\n",
    "ax.set_title(\"Performance Across Time Windows\", fontsize=12, pad=10, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Time Window\", fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Macro AUROC (95% CI)\", fontweight=\"bold\")\n",
    "\n",
    "# Logarithmic x-axis for context sizes\n",
    "# ax.set_xscale(\"log\")\n",
    "ax.set_xticks(time_windows_ticks)\n",
    "ax.set_xticklabels(time_windows, fontsize=10)\n",
    "ax.set_ylim(0.69, 0.81)\n",
    "ax.set_yticks(np.arange(0.70, 0.81, 0.05))\n",
    "\n",
    "# Improve grid\n",
    "# ax.grid(visible=True, which=\"both\", linestyle=\"-\", alpha=0.2)\n",
    "# ax.grid(True, which='minor', linestyle=':', alpha=0.2)\n",
    "\n",
    "# Format axes\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "\n",
    "# Plot Qwen data\n",
    "ax.plot(time_windows_ticks, qwen_means, label=\"GTE-Qwen2-7B\",\n",
    "        marker=marker_qwen, linestyle=\"-\", linewidth=1.5,\n",
    "        markersize=8, color=color_qwen,\n",
    "        markeredgecolor=\"white\", markeredgewidth=1.5)\n",
    "ax.fill_between(time_windows_ticks, qwen_lower, qwen_upper, color=color_qwen, alpha=0.15)\n",
    "\n",
    "# Plot Llama data\n",
    "ax.plot(time_windows_ticks, llama_means, label=\"LLM2Vec-Llama-3.1-8B\",\n",
    "        marker=marker_llama, linestyle=\"-\", linewidth=1.5,\n",
    "        markersize=8, color=color_llama,\n",
    "        markeredgecolor=\"white\", markeredgewidth=1.5)\n",
    "ax.fill_between(time_windows_ticks, llama_lower, llama_upper, color=color_llama, alpha=0.15)\n",
    "\n",
    "# Legend for model names\n",
    "legend_elements = [\n",
    "    plt.Line2D([0], [0], marker=marker_qwen, color=color_qwen, label=\"GTE-Qwen2-7B\", linestyle=\"None\", markersize=8),\n",
    "    plt.Line2D([0], [0], marker=marker_llama, color=color_llama, label=\"LLM2Vec-Llama-3.1-8B\", linestyle=\"None\", markersize=8),\n",
    "]\n",
    "# ax.legend(handles=legend_elements, loc=\"lower left\", frameon=False, fontsize=10, title=\"Model Names\")\n",
    "_plot_unified_legend(fig, np.array([[ax]]), fontsize=9)\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(output_path_png, dpi=300, bbox_inches='tight')\n",
    "plt.savefig(output_path_pdf, dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
